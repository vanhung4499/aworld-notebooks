{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb2b60e4",
   "metadata": {},
   "source": [
    "# AWorld MAS Task Execution\n",
    "\n",
    "This notebook demonstrates transparent, step-by-step agent execution for a GAIA benchmark task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc101c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Information\n",
    "task_id = \"8e867cd7-cff9-4e6c-867a-ff5ddc2550be\"\n",
    "level = 1\n",
    "question = \"\"\"How many studio albums were published by Mercedes Sosa between 2000 and 2009 (included)? You can use the latest 2022 version of english wikipedia.\"\"\"\n",
    "ground_truth = \"\"\"3\"\"\"\n",
    "file_name = \"\"\n",
    "annotator_tools = \"\"\"1. web browser\n",
    "2. google search\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TASK DETAILS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Task ID: {task_id}\")\n",
    "print(f\"Difficulty Level: {level}\")\n",
    "print(f\"Has File Attachment: {bool(file_name)}\")\n",
    "if file_name:\n",
    "    print(f\"  File: {file_name}\")\n",
    "print(f\"Annotator Tools Used: {annotator_tools if annotator_tools else 'None'}\")\n",
    "print()\n",
    "print(\"QUESTION:\")\n",
    "print(\"-\" * 80)\n",
    "print(question)\n",
    "print()\n",
    "print(\"GROUND TRUTH ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "print(ground_truth)\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6cb554",
   "metadata": {},
   "source": [
    "## Setup & Configuration\n",
    "\n",
    "Initialize the AWorld MAS framework with robust path detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Path detection and imports\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize variables\n",
    "agent_config = None\n",
    "mcp_config = {}\n",
    "available_servers = []\n",
    "\n",
    "# Current directory paths\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENVIRONMENT SETUP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Import AWorld modules\n",
    "try:\n",
    "    from aworld.agents.llm_agent import Agent\n",
    "    from aworld.config.conf import AgentConfig, TaskConfig\n",
    "    from aworld.core.task import Task\n",
    "    from aworld.runner import Runners\n",
    "    print(\"✓ AWorld modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ ERROR importing AWorld modules: {e}\")\n",
    "    print(\"  Make sure AWorld is installed: pip install aworld\")\n",
    "    print(\"  Or from GitHub: pip install git+https://github.com/inclusionAI/AWorld.git\")\n",
    "    raise\n",
    "\n",
    "# Load environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    # Search for .env file in common locations\n",
    "    possible_env_paths = [\n",
    "        current_dir / \".env\",\n",
    "        parent_dir / \".env\",\n",
    "        Path.home() / \".env\",\n",
    "    ]\n",
    "\n",
    "    env_loaded = False\n",
    "    for env_path in possible_env_paths:\n",
    "        if env_path.exists():\n",
    "            load_dotenv(env_path, override=True)\n",
    "            print(f\"✓ Loaded environment from: {env_path}\")\n",
    "            env_loaded = True\n",
    "            break\n",
    "\n",
    "    if not env_loaded:\n",
    "        print(\"⚠ No .env file found, using system environment variables\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⚠ python-dotenv not installed, using system environment variables\")\n",
    "\n",
    "# Load MCP configuration\n",
    "try:\n",
    "    possible_mcp_paths = [\n",
    "        current_dir / \"mcp.json\",\n",
    "        parent_dir / \"mcp.json\",\n",
    "        parent_dir / \"examples\" / \"gaia\" / \"mcp.json\",\n",
    "    ]\n",
    "\n",
    "    mcp_loaded = False\n",
    "    for mcp_path in possible_mcp_paths:\n",
    "        if mcp_path.exists():\n",
    "            with open(mcp_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                mcp_config = json.load(f)\n",
    "                available_servers = list(mcp_config.get(\"mcpServers\", {}).keys())\n",
    "                print(f\"✓ Loaded MCP config from: {mcp_path}\")\n",
    "                print(f\"  Available MCP servers: {available_servers}\")\n",
    "                mcp_loaded = True\n",
    "                break\n",
    "\n",
    "    if not mcp_loaded:\n",
    "        print(\"⚠ No mcp.json found, agent will run without MCP servers\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Error loading MCP config: {e}\")\n",
    "    print(\"  Agent will run without MCP servers\")\n",
    "\n",
    "# Create agent configuration\n",
    "try:\n",
    "    agent_config = AgentConfig(\n",
    "        llm_provider=os.getenv(\"LLM_PROVIDER\", \"openai\"),\n",
    "        llm_model_name=os.getenv(\"LLM_MODEL_NAME\", \"gpt-4o\"),\n",
    "        llm_base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "        llm_api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "        llm_temperature=float(os.getenv(\"LLM_TEMPERATURE\", \"0.0\")),\n",
    "    )\n",
    "    print(\"✓ Agent configuration created\")\n",
    "    print(f\"  Provider: {agent_config.llm_config.llm_provider}\")\n",
    "    print(f\"  Model: {agent_config.llm_config.llm_model_name}\")\n",
    "    print(f\"  Temperature: {agent_config.llm_config.llm_temperature}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ ERROR creating agent config: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6489048b",
   "metadata": {},
   "source": [
    "## Agent Initialization\n",
    "\n",
    "Create the GAIA super agent with MCP servers for tool execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a87535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GAIA super agent\n",
    "system_prompt = \"\"\"You are a helpful AI assistant tasked with answering questions from the GAIA benchmark.\n",
    "\n",
    "Your goal is to provide accurate, well-reasoned answers to complex questions that may require:\n",
    "- Web searches and browsing\n",
    "- File reading and analysis (PDF, Excel, images, code, etc.)\n",
    "- Mathematical computations\n",
    "- Multi-step reasoning\n",
    "- Tool usage\n",
    "\n",
    "When you have determined the final answer, provide it in this format:\n",
    "<answer>your answer here</answer>\n",
    "\n",
    "Be thorough, use available tools when needed, and show your reasoning.\"\"\"\n",
    "\n",
    "try:\n",
    "    super_agent = Agent(\n",
    "        conf=agent_config,\n",
    "        name=\"gaia_super_agent\",\n",
    "        system_prompt=system_prompt,\n",
    "        mcp_config=mcp_config,\n",
    "        mcp_servers=available_servers,\n",
    "        feedback_tool_result=True\n",
    "    )\n",
    "    print(\"✓ GAIA super agent created successfully\")\n",
    "    print(f\"  Agent name: {super_agent.name}\")\n",
    "    print(f\"  MCP servers: {super_agent.mcp_servers if super_agent.mcp_servers else 'None'}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"✗ ERROR creating agent: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a3982",
   "metadata": {},
   "source": [
    "## Task Execution\n",
    "\n",
    "Run the task with the agent and capture the full execution trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b884f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the task\n",
    "import time\n",
    "\n",
    "# Prepare question with file path if needed\n",
    "question_with_files = question\n",
    "dataset_path = \"/Users/kirito4499/Desktop/Projects/Python/aworld-notebooks/gaia_dataset/2023\"\n",
    "split = \"validation\"\n",
    "\n",
    "if file_name:\n",
    "    file_path = Path(dataset_path) / split / file_name\n",
    "    question_with_files += \"\"\n",
    "    print(f\"Task includes file attachment: {file_path}\")\n",
    "    print(f\"File exists: {file_path.exists()}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXECUTING TASK\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Starting agent execution...\")\n",
    "print()\n",
    "\n",
    "# Create and run task\n",
    "start_time = time.time()\n",
    "task_result = None\n",
    "task_response = None\n",
    "\n",
    "try:\n",
    "    task_obj = Task(\n",
    "        input=question_with_files,\n",
    "        agent=super_agent,\n",
    "        conf=TaskConfig()\n",
    "    )\n",
    "\n",
    "    print(f\"Task created with ID: {task_obj.id}\")\n",
    "    print(\"Running agent...\")\n",
    "    print()\n",
    "\n",
    "    # Execute task\n",
    "    task_result = Runners.sync_run_task(task=task_obj)\n",
    "    task_response = task_result[task_obj.id]\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"EXECUTION COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"✓ Status: {'Success' if task_response.success else 'Failed'}\")\n",
    "    print(f\"✓ Execution time: {execution_time:.2f} seconds\")\n",
    "    print(f\"✓ Steps taken: {len(task_response.trajectory) if task_response.trajectory else 'N/A'}\")\n",
    "    if hasattr(task_response, 'usage') and task_response.usage:\n",
    "        print(f\"✓ Token usage: {task_response.usage}\")\n",
    "    print()\n",
    "    print(\"AGENT ANSWER:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(task_response.answer)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"✗ ERROR during task execution: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb4ce5c",
   "metadata": {},
   "source": [
    "## Execution Trajectory\n",
    "\n",
    "Detailed step-by-step breakdown of agent actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display execution trajectory\n",
    "if task_response and hasattr(task_response, 'trajectory') and task_response.trajectory:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"TRAJECTORY: {len(task_response.trajectory)} STEPS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    for step_idx, step in enumerate(task_response.trajectory, 1):\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"STEP {step_idx}/{len(task_response.trajectory)}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        # Display step information based on type\n",
    "        if isinstance(step, dict):\n",
    "            for key, value in step.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(f\"Step data: {step}\")\n",
    "\n",
    "        print()\n",
    "else:\n",
    "    print(\"No trajectory data available\")\n",
    "    if task_response:\n",
    "        print(f\"Task response type: {type(task_response)}\")\n",
    "        print(f\"Available attributes: {dir(task_response)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e40a765",
   "metadata": {},
   "source": [
    "## MCP Tool Calls\n",
    "\n",
    "Detailed view of all tool executions during the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display tool calls\n",
    "if task_response and hasattr(task_response, 'trajectory') and task_response.trajectory:\n",
    "    tool_calls = []\n",
    "\n",
    "    # Extract tool calls from trajectory\n",
    "    for step_idx, step in enumerate(task_response.trajectory, 1):\n",
    "        if isinstance(step, dict):\n",
    "            # Check for tool-related keys\n",
    "            if 'tool_name' in step or 'action_name' in step:\n",
    "                tool_calls.append({\n",
    "                    'step': step_idx,\n",
    "                    'data': step\n",
    "                })\n",
    "\n",
    "    if tool_calls:\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"TOOL CALLS: {len(tool_calls)} total\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "\n",
    "        for call in tool_calls:\n",
    "            step_num = call['step']\n",
    "            data = call['data']\n",
    "\n",
    "            print(f\"{'─'*80}\")\n",
    "            print(f\"Tool Call at Step {step_num}\")\n",
    "            print(f\"{'─'*80}\")\n",
    "\n",
    "            tool_name = data.get('tool_name', 'Unknown')\n",
    "            action_name = data.get('action_name', 'Unknown')\n",
    "            params = data.get('params', {})\n",
    "            result = data.get('result', 'No result captured')\n",
    "\n",
    "            print(f\"Tool: {tool_name}\")\n",
    "            print(f\"Action: {action_name}\")\n",
    "            print(f\"\\nParameters:\")\n",
    "            for key, value in params.items():\n",
    "                value_str = str(value)\n",
    "                if len(value_str) > 200:\n",
    "                    value_str = value_str[:200] + \"...\"\n",
    "                print(f\"  {key}: {value_str}\")\n",
    "\n",
    "            print(f\"\\nResult:\")\n",
    "            result_str = str(result)\n",
    "            if len(result_str) > 500:\n",
    "                result_str = result_str[:500] + \"...\"\n",
    "            print(f\"  {result_str}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No tool calls found in trajectory\")\n",
    "else:\n",
    "    print(\"No trajectory available to extract tool calls\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399a4cd",
   "metadata": {},
   "source": [
    "## Agent Messages & LLM Interactions\n",
    "\n",
    "Detailed view of all agent communications and LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3befc44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display agent messages\n",
    "if task_response and hasattr(task_response, 'trajectory') and task_response.trajectory:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"AGENT MESSAGES & LLM CALLS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    for step_idx, step in enumerate(task_response.trajectory, 1):\n",
    "        print(f\"{'─'*80}\")\n",
    "        print(f\"Step {step_idx}: Message Details\")\n",
    "        print(f\"{'─'*80}\")\n",
    "\n",
    "        if isinstance(step, dict):\n",
    "            # Look for message-related fields\n",
    "            if 'role' in step or 'content' in step or 'message' in step:\n",
    "                role = step.get('role', 'unknown')\n",
    "                content = step.get('content', step.get('message', ''))\n",
    "\n",
    "                print(f\"Role: {role}\")\n",
    "                print(f\"Content:\")\n",
    "                content_str = str(content)\n",
    "                if len(content_str) > 1000:\n",
    "                    print(f\"  {content_str[:1000]}...\")\n",
    "                    print(f\"  ... ({len(content_str) - 1000} more characters)\")\n",
    "                else:\n",
    "                    print(f\"  {content_str}\")\n",
    "            else:\n",
    "                # Display all step data\n",
    "                for key, value in step.items():\n",
    "                    value_str = str(value)\n",
    "                    if len(value_str) > 300:\n",
    "                        value_str = value_str[:300] + \"...\"\n",
    "                    print(f\"{key}: {value_str}\")\n",
    "        else:\n",
    "            print(f\"Step type: {type(step)}\")\n",
    "            step_str = str(step)\n",
    "            if len(step_str) > 500:\n",
    "                print(f\"{step_str[:500]}...\")\n",
    "            else:\n",
    "                print(step_str)\n",
    "\n",
    "        print()\n",
    "else:\n",
    "    print(\"No trajectory available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d872b8",
   "metadata": {},
   "source": [
    "## Answer Validation\n",
    "\n",
    "Extract the agent's answer and compare with ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and validate answer\n",
    "import re\n",
    "import string\n",
    "\n",
    "def normalize_str(input_str, remove_punct=True):\n",
    "    \"\"\"Normalize string for comparison.\"\"\"\n",
    "    no_spaces = re.sub(r\"\\s\", \"\", input_str)\n",
    "    if remove_punct:\n",
    "        translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return no_spaces.lower().translate(translator)\n",
    "    else:\n",
    "        return no_spaces.lower()\n",
    "\n",
    "def normalize_number_str(number_str):\n",
    "    \"\"\"Normalize number string.\"\"\"\n",
    "    for char in [\"$\", \"%\", \",\"]:\n",
    "        number_str = number_str.replace(char, \"\")\n",
    "    try:\n",
    "        return float(number_str)\n",
    "    except ValueError:\n",
    "        return float(\"inf\")\n",
    "\n",
    "def is_float(element):\n",
    "    \"\"\"Check if element can be converted to float.\"\"\"\n",
    "    try:\n",
    "        float(element)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def question_scorer(model_answer, ground_truth):\n",
    "    \"\"\"Score the model answer against ground truth.\"\"\"\n",
    "    try:\n",
    "        if is_float(ground_truth):\n",
    "            # Numeric comparison\n",
    "            normalized_answer = normalize_number_str(model_answer)\n",
    "            return normalized_answer == float(ground_truth)\n",
    "        elif any(char in ground_truth for char in [\",\", \";\"]):\n",
    "            # List comparison\n",
    "            gt_elems = re.split(r\"[,;]\", ground_truth)\n",
    "            ma_elems = re.split(r\"[,;]\", model_answer)\n",
    "\n",
    "            if len(gt_elems) != len(ma_elems):\n",
    "                return False\n",
    "\n",
    "            comparisons = []\n",
    "            for ma_elem, gt_elem in zip(ma_elems, gt_elems):\n",
    "                if is_float(gt_elem):\n",
    "                    normalized_ma_elem = normalize_number_str(ma_elem)\n",
    "                    comparisons.append(normalized_ma_elem == float(gt_elem))\n",
    "                else:\n",
    "                    ma_elem = normalize_str(ma_elem, remove_punct=False)\n",
    "                    gt_elem = normalize_str(gt_elem, remove_punct=False)\n",
    "                    comparisons.append(ma_elem == gt_elem)\n",
    "            return all(comparisons)\n",
    "        else:\n",
    "            # String comparison\n",
    "            ma_elem = normalize_str(model_answer)\n",
    "            gt_elem = normalize_str(ground_truth)\n",
    "            return ma_elem == gt_elem\n",
    "    except Exception as e:\n",
    "        print(f\"Error during validation: {e}\")\n",
    "        return False\n",
    "\n",
    "# Extract answer\n",
    "extracted_answer = None\n",
    "if task_response:\n",
    "    agent_response = task_response.answer\n",
    "\n",
    "    # Try to extract answer from <answer> tags\n",
    "    match = re.search(r\"<answer>(.*?)</answer>\", agent_response, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_answer = match.group(1).strip()\n",
    "        print(\"✓ Extracted answer from <answer> tags\")\n",
    "    else:\n",
    "        # Fallback: use full response\n",
    "        extracted_answer = agent_response.strip()\n",
    "        print(\"⚠ No <answer> tags found, using full response\")\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ANSWER EXTRACTION\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Extracted Answer:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(extracted_answer)\n",
    "    print()\n",
    "    print(\"Ground Truth:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(ground_truth)\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    # Validate\n",
    "    is_correct = question_scorer(extracted_answer, ground_truth)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"VALIDATION RESULT\")\n",
    "    print(\"=\" * 80)\n",
    "    if is_correct:\n",
    "        print(\"✅ PASS - Answer matches ground truth!\")\n",
    "    else:\n",
    "        print(\"❌ FAIL - Answer does not match ground truth\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Display comparison details\n",
    "    print()\n",
    "    print(\"Comparison Details:\")\n",
    "    print(f\"  Task ID: {task_id}\")\n",
    "    print(f\"  Level: {level}\")\n",
    "    print(f\"  Correct: {is_correct}\")\n",
    "else:\n",
    "    print(\"✗ No task response available for validation\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
