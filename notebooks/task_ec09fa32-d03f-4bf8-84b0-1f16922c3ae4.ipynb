{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d787752",
   "metadata": {},
   "source": [
    "# AWorld MAS Task Execution\n",
    "\n",
    "This notebook demonstrates transparent, step-by-step agent execution for a GAIA benchmark task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a8d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Information\n",
    "task_id = \"ec09fa32-d03f-4bf8-84b0-1f16922c3ae4\"\n",
    "level = 1\n",
    "question = \"\"\"Here's a fun riddle that I think you'll enjoy.\n",
    "\n",
    "You have been selected to play the final round of the hit new game show \"Pick That Ping-Pong\". In this round, you will be competing for a large cash prize. Your job will be to pick one of several different numbered ping-pong balls, and then the game will commence. The host describes how the game works.\n",
    "\n",
    "A device consisting of a winding clear ramp and a series of pistons controls the outcome of the game. The ramp feeds balls onto a platform. The platform has room for three ping-pong balls at a time. The three balls on the platform are each aligned with one of three pistons. At each stage of the game, one of the three pistons will randomly fire, ejecting the ball it strikes. If the piston ejects the ball in the first position on the platform the balls in the second and third position on the platform each advance one space, and the next ball on the ramp advances to the third position. If the piston ejects the ball in the second position, the ball in the first position is released and rolls away, the ball in the third position advances two spaces to occupy the first position, and the next two balls on the ramp advance to occupy the second and third positions on the platform. If the piston ejects the ball in the third position, the ball in the first position is released and rolls away, the ball in the second position advances one space to occupy the first position, and the next two balls on the ramp advance to occupy the second and third positions on the platform.\n",
    "\n",
    "The ramp begins with 100 numbered ping-pong balls, arranged in ascending order from 1 to 100. The host activates the machine and the first three balls, numbered 1, 2, and 3, advance to the platform. Before the random firing of the pistons begins, you are asked which of the 100 balls you would like to pick. If your pick is ejected by one of the pistons, you win the grand prize, $10,000.\n",
    "\n",
    "Which ball should you choose to maximize your odds of winning the big prize? Please provide your answer as the number of the ball selected.\"\"\"\n",
    "ground_truth = \"\"\"3\"\"\"\n",
    "file_name = \"\"\n",
    "annotator_tools = \"\"\"None\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TASK DETAILS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Task ID: {task_id}\")\n",
    "print(f\"Difficulty Level: {level}\")\n",
    "print(f\"Has File Attachment: {bool(file_name)}\")\n",
    "if file_name:\n",
    "    print(f\"  File: {file_name}\")\n",
    "print(f\"Annotator Tools Used: {annotator_tools if annotator_tools else 'None'}\")\n",
    "print()\n",
    "print(\"QUESTION:\")\n",
    "print(\"-\" * 80)\n",
    "print(question)\n",
    "print()\n",
    "print(\"GROUND TRUTH ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "print(ground_truth)\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f232afb",
   "metadata": {},
   "source": [
    "## Setup & Configuration\n",
    "\n",
    "Initialize the AWorld MAS framework with robust path detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Path detection and imports\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize variables\n",
    "agent_config = None\n",
    "mcp_config = {}\n",
    "available_servers = []\n",
    "\n",
    "# Current directory paths\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENVIRONMENT SETUP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Import AWorld modules\n",
    "try:\n",
    "    from aworld.agents.llm_agent import Agent\n",
    "    from aworld.config.conf import AgentConfig, TaskConfig\n",
    "    from aworld.core.task import Task\n",
    "    from aworld.runner import Runners\n",
    "    print(\"✓ AWorld modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ ERROR importing AWorld modules: {e}\")\n",
    "    print(\"  Make sure AWorld is installed: pip install aworld\")\n",
    "    print(\"  Or from GitHub: pip install git+https://github.com/inclusionAI/AWorld.git\")\n",
    "    raise\n",
    "\n",
    "# Load environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    # Search for .env file in common locations\n",
    "    possible_env_paths = [\n",
    "        current_dir / \".env\",\n",
    "        parent_dir / \".env\",\n",
    "        Path.home() / \".env\",\n",
    "    ]\n",
    "\n",
    "    env_loaded = False\n",
    "    for env_path in possible_env_paths:\n",
    "        if env_path.exists():\n",
    "            load_dotenv(env_path, override=True)\n",
    "            print(f\"✓ Loaded environment from: {env_path}\")\n",
    "            env_loaded = True\n",
    "            break\n",
    "\n",
    "    if not env_loaded:\n",
    "        print(\"⚠ No .env file found, using system environment variables\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⚠ python-dotenv not installed, using system environment variables\")\n",
    "\n",
    "# Load MCP configuration\n",
    "try:\n",
    "    possible_mcp_paths = [\n",
    "        current_dir / \"mcp.json\",\n",
    "        parent_dir / \"mcp.json\",\n",
    "        parent_dir / \"examples\" / \"gaia\" / \"mcp.json\",\n",
    "    ]\n",
    "\n",
    "    mcp_loaded = False\n",
    "    for mcp_path in possible_mcp_paths:\n",
    "        if mcp_path.exists():\n",
    "            with open(mcp_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                mcp_config = json.load(f)\n",
    "                available_servers = list(mcp_config.get(\"mcpServers\", {}).keys())\n",
    "                print(f\"✓ Loaded MCP config from: {mcp_path}\")\n",
    "                print(f\"  Available MCP servers: {available_servers}\")\n",
    "                mcp_loaded = True\n",
    "                break\n",
    "\n",
    "    if not mcp_loaded:\n",
    "        print(\"⚠ No mcp.json found, agent will run without MCP servers\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Error loading MCP config: {e}\")\n",
    "    print(\"  Agent will run without MCP servers\")\n",
    "\n",
    "# Create agent configuration\n",
    "try:\n",
    "    agent_config = AgentConfig(\n",
    "        llm_provider=os.getenv(\"LLM_PROVIDER\", \"openai\"),\n",
    "        llm_model_name=os.getenv(\"LLM_MODEL_NAME\", \"gpt-4o\"),\n",
    "        llm_base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "        llm_api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "        llm_temperature=float(os.getenv(\"LLM_TEMPERATURE\", \"0.0\")),\n",
    "    )\n",
    "    print(\"✓ Agent configuration created\")\n",
    "    print(f\"  Provider: {agent_config.llm_config.llm_provider}\")\n",
    "    print(f\"  Model: {agent_config.llm_config.llm_model_name}\")\n",
    "    print(f\"  Temperature: {agent_config.llm_config.llm_temperature}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ ERROR creating agent config: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5beeea6",
   "metadata": {},
   "source": [
    "## Agent Initialization\n",
    "\n",
    "Create the GAIA super agent with MCP servers for tool execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aadb1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GAIA super agent\n",
    "system_prompt = \"\"\"You are a helpful AI assistant tasked with answering questions from the GAIA benchmark.\n",
    "\n",
    "Your goal is to provide accurate, well-reasoned answers to complex questions that may require:\n",
    "- Web searches and browsing\n",
    "- File reading and analysis (PDF, Excel, images, code, etc.)\n",
    "- Mathematical computations\n",
    "- Multi-step reasoning\n",
    "- Tool usage\n",
    "\n",
    "When you have determined the final answer, provide it in this format:\n",
    "<answer>your answer here</answer>\n",
    "\n",
    "Be thorough, use available tools when needed, and show your reasoning.\"\"\"\n",
    "\n",
    "try:\n",
    "    super_agent = Agent(\n",
    "        conf=agent_config,\n",
    "        name=\"gaia_super_agent\",\n",
    "        system_prompt=system_prompt,\n",
    "        mcp_config=mcp_config,\n",
    "        mcp_servers=available_servers,\n",
    "        feedback_tool_result=True\n",
    "    )\n",
    "    print(\"✓ GAIA super agent created successfully\")\n",
    "    print(f\"  Agent name: {super_agent.name}\")\n",
    "    print(f\"  MCP servers: {super_agent.mcp_servers if super_agent.mcp_servers else 'None'}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"✗ ERROR creating agent: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa7a1d1",
   "metadata": {},
   "source": [
    "## Task Execution\n",
    "\n",
    "Run the task with the agent and capture the full execution trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd995542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the task\n",
    "import time\n",
    "\n",
    "# Prepare question with file path if needed\n",
    "question_with_files = question\n",
    "dataset_path = \"/Users/kirito4499/Desktop/Projects/Python/aworld-notebooks/gaia_dataset/2023\"\n",
    "split = \"validation\"\n",
    "\n",
    "if file_name:\n",
    "    file_path = Path(dataset_path) / split / file_name\n",
    "    question_with_files += \"\"\n",
    "    print(f\"Task includes file attachment: {file_path}\")\n",
    "    print(f\"File exists: {file_path.exists()}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXECUTING TASK\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Starting agent execution...\")\n",
    "print()\n",
    "\n",
    "# Create and run task\n",
    "start_time = time.time()\n",
    "task_result = None\n",
    "task_response = None\n",
    "\n",
    "try:\n",
    "    task_obj = Task(\n",
    "        input=question_with_files,\n",
    "        agent=super_agent,\n",
    "        conf=TaskConfig()\n",
    "    )\n",
    "\n",
    "    print(f\"Task created with ID: {task_obj.id}\")\n",
    "    print(\"Running agent...\")\n",
    "    print()\n",
    "\n",
    "    # Execute task\n",
    "    task_result = Runners.sync_run_task(task=task_obj)\n",
    "    task_response = task_result[task_obj.id]\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"EXECUTION COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"✓ Status: {'Success' if task_response.success else 'Failed'}\")\n",
    "    print(f\"✓ Execution time: {execution_time:.2f} seconds\")\n",
    "    print(f\"✓ Steps taken: {len(task_response.trajectory) if task_response.trajectory else 'N/A'}\")\n",
    "    if hasattr(task_response, 'usage') and task_response.usage:\n",
    "        print(f\"✓ Token usage: {task_response.usage}\")\n",
    "    print()\n",
    "    print(\"AGENT ANSWER:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(task_response.answer)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"✗ ERROR during task execution: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db5c9a5",
   "metadata": {},
   "source": [
    "## Execution Trajectory\n",
    "\n",
    "Detailed step-by-step breakdown of agent actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b15618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display execution trajectory\n",
    "if task_response and hasattr(task_response, 'trajectory') and task_response.trajectory:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"TRAJECTORY: {len(task_response.trajectory)} STEPS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    for step_idx, step in enumerate(task_response.trajectory, 1):\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"STEP {step_idx}/{len(task_response.trajectory)}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        # Display step information based on type\n",
    "        if isinstance(step, dict):\n",
    "            for key, value in step.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(f\"Step data: {step}\")\n",
    "\n",
    "        print()\n",
    "else:\n",
    "    print(\"No trajectory data available\")\n",
    "    if task_response:\n",
    "        print(f\"Task response type: {type(task_response)}\")\n",
    "        print(f\"Available attributes: {dir(task_response)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756b5f6",
   "metadata": {},
   "source": [
    "## MCP Tool Calls\n",
    "\n",
    "Detailed view of all tool executions during the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd09b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display tool calls\n",
    "if task_response and hasattr(task_response, 'trajectory') and task_response.trajectory:\n",
    "    tool_calls = []\n",
    "\n",
    "    # Extract tool calls from trajectory\n",
    "    for step_idx, step in enumerate(task_response.trajectory, 1):\n",
    "        if isinstance(step, dict):\n",
    "            # Check for tool-related keys\n",
    "            if 'tool_name' in step or 'action_name' in step:\n",
    "                tool_calls.append({\n",
    "                    'step': step_idx,\n",
    "                    'data': step\n",
    "                })\n",
    "\n",
    "    if tool_calls:\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"TOOL CALLS: {len(tool_calls)} total\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "\n",
    "        for call in tool_calls:\n",
    "            step_num = call['step']\n",
    "            data = call['data']\n",
    "\n",
    "            print(f\"{'─'*80}\")\n",
    "            print(f\"Tool Call at Step {step_num}\")\n",
    "            print(f\"{'─'*80}\")\n",
    "\n",
    "            tool_name = data.get('tool_name', 'Unknown')\n",
    "            action_name = data.get('action_name', 'Unknown')\n",
    "            params = data.get('params', {})\n",
    "            result = data.get('result', 'No result captured')\n",
    "\n",
    "            print(f\"Tool: {tool_name}\")\n",
    "            print(f\"Action: {action_name}\")\n",
    "            print(f\"\\nParameters:\")\n",
    "            for key, value in params.items():\n",
    "                value_str = str(value)\n",
    "                if len(value_str) > 200:\n",
    "                    value_str = value_str[:200] + \"...\"\n",
    "                print(f\"  {key}: {value_str}\")\n",
    "\n",
    "            print(f\"\\nResult:\")\n",
    "            result_str = str(result)\n",
    "            if len(result_str) > 500:\n",
    "                result_str = result_str[:500] + \"...\"\n",
    "            print(f\"  {result_str}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No tool calls found in trajectory\")\n",
    "else:\n",
    "    print(\"No trajectory available to extract tool calls\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c276f3",
   "metadata": {},
   "source": [
    "## Agent Messages & LLM Interactions\n",
    "\n",
    "Detailed view of all agent communications and LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a208dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display agent messages\n",
    "if task_response and hasattr(task_response, 'trajectory') and task_response.trajectory:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"AGENT MESSAGES & LLM CALLS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    for step_idx, step in enumerate(task_response.trajectory, 1):\n",
    "        print(f\"{'─'*80}\")\n",
    "        print(f\"Step {step_idx}: Message Details\")\n",
    "        print(f\"{'─'*80}\")\n",
    "\n",
    "        if isinstance(step, dict):\n",
    "            # Look for message-related fields\n",
    "            if 'role' in step or 'content' in step or 'message' in step:\n",
    "                role = step.get('role', 'unknown')\n",
    "                content = step.get('content', step.get('message', ''))\n",
    "\n",
    "                print(f\"Role: {role}\")\n",
    "                print(f\"Content:\")\n",
    "                content_str = str(content)\n",
    "                if len(content_str) > 1000:\n",
    "                    print(f\"  {content_str[:1000]}...\")\n",
    "                    print(f\"  ... ({len(content_str) - 1000} more characters)\")\n",
    "                else:\n",
    "                    print(f\"  {content_str}\")\n",
    "            else:\n",
    "                # Display all step data\n",
    "                for key, value in step.items():\n",
    "                    value_str = str(value)\n",
    "                    if len(value_str) > 300:\n",
    "                        value_str = value_str[:300] + \"...\"\n",
    "                    print(f\"{key}: {value_str}\")\n",
    "        else:\n",
    "            print(f\"Step type: {type(step)}\")\n",
    "            step_str = str(step)\n",
    "            if len(step_str) > 500:\n",
    "                print(f\"{step_str[:500]}...\")\n",
    "            else:\n",
    "                print(step_str)\n",
    "\n",
    "        print()\n",
    "else:\n",
    "    print(\"No trajectory available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4726d01f",
   "metadata": {},
   "source": [
    "## Answer Validation\n",
    "\n",
    "Extract the agent's answer and compare with ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and validate answer\n",
    "import re\n",
    "import string\n",
    "\n",
    "def normalize_str(input_str, remove_punct=True):\n",
    "    \"\"\"Normalize string for comparison.\"\"\"\n",
    "    no_spaces = re.sub(r\"\\s\", \"\", input_str)\n",
    "    if remove_punct:\n",
    "        translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return no_spaces.lower().translate(translator)\n",
    "    else:\n",
    "        return no_spaces.lower()\n",
    "\n",
    "def normalize_number_str(number_str):\n",
    "    \"\"\"Normalize number string.\"\"\"\n",
    "    for char in [\"$\", \"%\", \",\"]:\n",
    "        number_str = number_str.replace(char, \"\")\n",
    "    try:\n",
    "        return float(number_str)\n",
    "    except ValueError:\n",
    "        return float(\"inf\")\n",
    "\n",
    "def is_float(element):\n",
    "    \"\"\"Check if element can be converted to float.\"\"\"\n",
    "    try:\n",
    "        float(element)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def question_scorer(model_answer, ground_truth):\n",
    "    \"\"\"Score the model answer against ground truth.\"\"\"\n",
    "    try:\n",
    "        if is_float(ground_truth):\n",
    "            # Numeric comparison\n",
    "            normalized_answer = normalize_number_str(model_answer)\n",
    "            return normalized_answer == float(ground_truth)\n",
    "        elif any(char in ground_truth for char in [\",\", \";\"]):\n",
    "            # List comparison\n",
    "            gt_elems = re.split(r\"[,;]\", ground_truth)\n",
    "            ma_elems = re.split(r\"[,;]\", model_answer)\n",
    "\n",
    "            if len(gt_elems) != len(ma_elems):\n",
    "                return False\n",
    "\n",
    "            comparisons = []\n",
    "            for ma_elem, gt_elem in zip(ma_elems, gt_elems):\n",
    "                if is_float(gt_elem):\n",
    "                    normalized_ma_elem = normalize_number_str(ma_elem)\n",
    "                    comparisons.append(normalized_ma_elem == float(gt_elem))\n",
    "                else:\n",
    "                    ma_elem = normalize_str(ma_elem, remove_punct=False)\n",
    "                    gt_elem = normalize_str(gt_elem, remove_punct=False)\n",
    "                    comparisons.append(ma_elem == gt_elem)\n",
    "            return all(comparisons)\n",
    "        else:\n",
    "            # String comparison\n",
    "            ma_elem = normalize_str(model_answer)\n",
    "            gt_elem = normalize_str(ground_truth)\n",
    "            return ma_elem == gt_elem\n",
    "    except Exception as e:\n",
    "        print(f\"Error during validation: {e}\")\n",
    "        return False\n",
    "\n",
    "# Extract answer\n",
    "extracted_answer = None\n",
    "if task_response:\n",
    "    agent_response = task_response.answer\n",
    "\n",
    "    # Try to extract answer from <answer> tags\n",
    "    match = re.search(r\"<answer>(.*?)</answer>\", agent_response, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_answer = match.group(1).strip()\n",
    "        print(\"✓ Extracted answer from <answer> tags\")\n",
    "    else:\n",
    "        # Fallback: use full response\n",
    "        extracted_answer = agent_response.strip()\n",
    "        print(\"⚠ No <answer> tags found, using full response\")\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ANSWER EXTRACTION\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Extracted Answer:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(extracted_answer)\n",
    "    print()\n",
    "    print(\"Ground Truth:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(ground_truth)\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    # Validate\n",
    "    is_correct = question_scorer(extracted_answer, ground_truth)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"VALIDATION RESULT\")\n",
    "    print(\"=\" * 80)\n",
    "    if is_correct:\n",
    "        print(\"✅ PASS - Answer matches ground truth!\")\n",
    "    else:\n",
    "        print(\"❌ FAIL - Answer does not match ground truth\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Display comparison details\n",
    "    print()\n",
    "    print(\"Comparison Details:\")\n",
    "    print(f\"  Task ID: {task_id}\")\n",
    "    print(f\"  Level: {level}\")\n",
    "    print(f\"  Correct: {is_correct}\")\n",
    "else:\n",
    "    print(\"✗ No task response available for validation\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
